{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn \n",
    "import scipy\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import KFold, train_test_split, cross_val_score, StratifiedKFold, LabelKFold, ShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from mhcflurry.amino_acid import common_amino_acids\n",
    "from mhcflurry import dataset\n",
    "from mhcflurry.dataset import Dataset\n",
    "import matplotlib.pyplot as plt \n",
    "% matplotlib inline\n",
    "import numpy as np\n",
    "import math \n",
    "from mhcflurry import peptide_encoding, amino_acid\n",
    "import statsmodels.api as sm\n",
    "from keras import models, layers, optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Input, merge, Convolution1D, AveragePooling1D, Activation, Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.engine import topology\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = Dataset.from_csv(\"bdata.2009.mhci.public.1.txt\")\n",
    "ds_h = ds.slice(ds.alleles == 'HLA-A0201')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_table(\"bdata.2009.mhci.public.1.txt\")\n",
    "\n",
    "df['log_meas']=1-np.log(df['meas'])/math.log(50000)\n",
    "df['peptide_length'] = df['sequence'].str.len()\n",
    "\n",
    "\n",
    "max_len=df['sequence'].str.len().max()\n",
    "n_peptides = df['sequence'].count()\n",
    "\n",
    "def amino_acid_hotshot_encoding(s):\n",
    "    return common_amino_acids.hotshot_encoding([s],len(s)).flatten().astype(int)\n",
    "df['hotshot_encoded_peptides'] = df.sequence.apply(lambda seq: amino_acid_hotshot_encoding(seq))\n",
    "\n",
    "def amino_acid_index_encoding(s, maxlen):\n",
    "    a = 1+common_amino_acids.index_encoding([s],len(s)).flatten()\n",
    "    return np.concatenate([a, np.zeros(maxlen-len(a),dtype=int)])\n",
    "df['index_encoded_peptides'] = df.sequence.apply(lambda seq: amino_acid_index_encoding(seq, max_len))\n",
    "\n",
    "def measured_affinity_less_than(Y,k):\n",
    "    IC50 = 50000**(1-Y)\n",
    "    return (IC50 < k).astype(int) \n",
    "\n",
    "def affinity_label(Y):\n",
    "    return measured_affinity_less_than(Y,50) + measured_affinity_less_than(Y,500) + measured_affinity_less_than(Y,5000) + measured_affinity_less_than(Y,50000)\n",
    "\n",
    "df['affinity_label'] = affinity_label(df['log_meas'])\n",
    "df_h = df[df['mhc']=='HLA-A-0201'][['hotshot_encoded_peptides','index_encoded_peptides','log_meas','peptide_length']]\n",
    "X = np.array(list(df_h['index_encoded_peptides']))\n",
    "y = np.array(list(df_h['log_meas']))\n",
    "y[y<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regroup_together(affinities, weights , original_indices):\n",
    "    affinities = affinities.ravel()\n",
    "    weights = weights.ravel()\n",
    "    assert affinities.shape == weights.shape, \"%s should be %s\" % (affinities.shape, weights.shape)\n",
    "    assert affinities.shape == original_indices.shape\n",
    "    assert len(affinities) == len(affinities.ravel())\n",
    "    weighted_affinities = (affinities * weights)\n",
    "    index_set = set(original_indices)\n",
    "    n_indices = len(index_set)\n",
    "    result_order = {original_index: i for (i, original_index) in enumerate(sorted(index_set))}\n",
    "    result = np.zeros(n_indices)\n",
    "    for i, x in enumerate(weighted_affinities):\n",
    "        result_idx = result_order[original_indices[i]]\n",
    "        result[result_idx] += x\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slicing(dataset,index, i):\n",
    "    return dataset.slice(index).kmer_index_encoding()[i]\n",
    "def label_transform(array):\n",
    "    result = 1-np.log(array)/math.log(50000)\n",
    "    result[result<0]=0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_to_hotshot_encoding(index_encoded_nine_mer):\n",
    "    result = np.zeros((9,21))\n",
    "    for position, amino_acid in enumerate(index_encoded_nine_mer):\n",
    "        result[position][amino_acid]= 1\n",
    "    return result.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.934364546634 0.935618120947 0\n",
      "0.937249104864 0.931697462195 1\n",
      "0.93611466352 0.925100013517 2\n"
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(KFold(len(ds_h),folds, shuffle=True)):\n",
    "    X_train_index = slicing(ds_h,train_idx,0) # we to transform these into hotshot encoding\n",
    "    y_train = label_transform(slicing(ds_h,train_idx,1))\n",
    "    X_train = np.apply_along_axis(index_to_hotshot_encoding,1, X_train_index )\n",
    "    \n",
    "    X_test_index = slicing(ds_h,test_idx,0) # we to transform these into hotshot encoding\n",
    "    y_test = label_transform(slicing(ds_h,test_idx,1))\n",
    "    X_test = np.apply_along_axis(index_to_hotshot_encoding,1, X_test_index )\n",
    "    \n",
    "    weights_train = slicing(ds_h,train_idx,2)\n",
    "    weights_test = slicing(ds_h,test_idx,2)\n",
    "    \n",
    "    original_indices_train = slicing(ds_h,train_idx,3)\n",
    "    original_indices_test = slicing(ds_h,test_idx,3)\n",
    "    \n",
    "    train_real_labels = regroup_together(y_train, weights_train , original_indices_train)\n",
    "    test_real_labels = regroup_together(y_test, weights_test , original_indices_test)\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train,y_train)\n",
    "    \n",
    "    train_pred_grouped = regroup_together(lr.predict(X_train), weights_train, original_indices_train)\n",
    "    test_pred_grouped = regroup_together(lr.predict(X_test), weights_test, original_indices_test)\n",
    "    \n",
    "    train_lr_auc = roc_auc_score(measured_affinity_less_than(train_real_labels,500), train_pred_grouped)     \n",
    "    test_lr_auc = roc_auc_score(measured_affinity_less_than(test_real_labels,500), test_pred_grouped)\n",
    "    \n",
    "    print(train_lr_auc, test_lr_auc, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
